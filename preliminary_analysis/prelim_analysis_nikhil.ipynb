{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "os.chdir(\"..\")\n",
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# <STEP 1> load cases\n",
    "\n",
    "# TODO: using full case hits api limit quickly, is case metadata enough?\n",
    "# TODO: get unlimited API access\n",
    "response = utils.get_request_caselaw(\"https://api.case.law/v1/cases/?search='cornell university'&full_case=TRUE\").json() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('output.json', 'w') as f:\n",
    "    json.dump(response, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Structure of `response` dict:\n",
    "```\n",
    "{  \n",
    "    \"count\"    : total number of matching cases  \n",
    "    \"next\"     : url to query for next 100 cases  \n",
    "    \"previous\" : url to query for previous 100 cases  \n",
    "    \"results\"  : [ (max length 100)\n",
    "        {\n",
    "            \"name\"          : **case name**\n",
    "            \"decision_date\" : case date\n",
    "            \"citations\"     : [\n",
    "                {\n",
    "                    \"cite\" : name of law\n",
    "                    \"type\" : ??\n",
    "                },\n",
    "                ...\n",
    "            ]\n",
    "            \"frontend_url\"  : clean look at case\n",
    "            \"casebody\"      : { (if full_case=FALSE, this field is not present)\n",
    "                \"status\" : should equal ok\n",
    "                \"data\"   : {\n",
    "                    \"opinions\"    : [ (for non-supreme court cases, just one opinion)\n",
    "                        {\n",
    "                            \"author\" : name of judge\n",
    "                            \"type\"   : indicates type of opinion (majority/dissent/etc)\n",
    "                            \"text\"   : opinion text\n",
    "                        },\n",
    "                        ...\n",
    "                    ]\n",
    "                    \"head_matter\" : **case description text**\n",
    "            }\n",
    "        },\n",
    "        ...\n",
    "    ]\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "cases = response['results']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# <STEP 2> pre-processing\n",
    "\n",
    "for case in cases:\n",
    "    # get rid of non-ok cases\n",
    "    if case['casebody']['status'] != 'ok':\n",
    "        cases.remove(case)\n",
    "        continue\n",
    "\n",
    "    # get rid of \\n from case description\n",
    "    case['casebody']['data']['head_matter'] = case['casebody']['data']['head_matter'].replace(\"\\n\", \" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# <STEP 3> set up data structures\n",
    "\n",
    "# key=case name, value=case text \n",
    "cases_dict = {case['name']: case['casebody']['data']['head_matter'] for case in cases if case['casebody']['status'] == 'ok'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get total number of tokens\n",
    "total_tokens = {}\n",
    "for text in cases_dict.values():\n",
    "    for token in [x for x in re.findall(r\"[a-z]+\", text.lower())]:\n",
    "        try:\n",
    "            total_tokens[token] += 1\n",
    "        except KeyError:\n",
    "            total_tokens[token] = 1\n",
    "            \n",
    "# filter tokens that appear less than 10 times\n",
    "total_tokens = {k:v for k,v in total_tokens.items() if v > 10}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "# useful data structures\n",
    "token_to_idx_dict = {v:k for k,v in enumerate(total_tokens.keys())}\n",
    "valid_tokens = set(total_tokens.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[98., 98., 14., ...,  0.,  0.,  0.],\n",
       "       [ 5.,  5.,  1., ...,  0.,  0.,  0.],\n",
       "       [ 4.,  5.,  3., ...,  0.,  0.,  0.],\n",
       "       ...,\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.]])"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2d array of token frequency per case\n",
    "cases_tokens = np.zeros((len(cases), len(total_tokens)))\n",
    "for idx, (case_name, case_text) in enumerate(cases_dict.items()):\n",
    "    for token in [x for x in re.findall(r\"[a-z]+\", case_text.lower())]:\n",
    "        if token in valid_tokens:\n",
    "            cases_tokens[idx][token_to_idx_dict[token]] += 1\n",
    "    \n",
    "cases_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
