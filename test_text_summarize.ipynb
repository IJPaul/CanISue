{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import os\n",
    "import utils\n",
    "import json\n",
    "import numpy as np\n",
    "import math\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from collections import Counter\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "import string \n",
    "import re\n",
    "\n",
    "def mean_case_length(case_json): \n",
    "    \"\"\"\n",
    "    Returns the average length of cases (in sentences)\n",
    "    case_json: dict with fields case_name, case_summary, score\n",
    "    \"\"\"\n",
    "    lengths_list = list()\n",
    "    for case in case_json:\n",
    "        length_of_text = len(sent_tokenize(case['case_summary']))\n",
    "        lengths_list.append(length_of_text)\n",
    "    return np.mean(lengths_list)\n",
    "\n",
    "\n",
    "def std_dev_case_length(case_json): \n",
    "    \"\"\"\n",
    "    Returns the std dev of length of cases (in sentences)\n",
    "    case_json: dict with fields case_name, case_summary, score\n",
    "    \"\"\"\n",
    "    lengths_list = list()\n",
    "    for case in case_json:\n",
    "        length_of_text = len(sent_tokenize(case['case_summary']))\n",
    "        lengths_list.append(length_of_text)\n",
    "    return np.std(lengths_list)\n",
    "\n",
    "\n",
    "# =====TEXT SUMMARIZATION METHODS======\n",
    "\n",
    "def contains_digit(line):\n",
    "    \"\"\"\n",
    "    Returns true if a string contains a digit character, False otherwise\n",
    "    \n",
    "    line: a str\n",
    "    \"\"\"\n",
    "    return any(char.isdigit() for char in line)\n",
    "\n",
    "def contains_punctuation(line):\n",
    "    \"\"\"\n",
    "    Returns true if a string contains a punctuation character, False otherwise\n",
    "    \n",
    "    line: a str\n",
    "    \"\"\"\n",
    "    return any(char in string.punctuation for char in line)\n",
    "    \n",
    "\n",
    "\n",
    "def create_tf_dict(text_string):\n",
    "    \"\"\"\n",
    "    Returns a term-frequency dict with (term, frequency) key-value pairs\n",
    "    \n",
    "    text_string: a str to create the term-freq dict from\n",
    "    \"\"\"\n",
    "    # Remove stop words\n",
    "    text_string = text_string.lower()\n",
    "    stop_words = set(stopwords.words(\"english\"))\n",
    "    \n",
    "    words = word_tokenize(text_string)\n",
    "    \n",
    "    # Reduce words to their root form\n",
    "    stem = PorterStemmer()\n",
    "    \n",
    "    # Create dictionary for the word frequency table\n",
    "    tf_dict = dict()\n",
    "    for wd in words:\n",
    "        # Remove puncutation by turning puncutation to ''\n",
    "        wd = wd.translate(str.maketrans('', '', string.punctuation))\n",
    "        # Stem\n",
    "        wd = stem.stem(wd)\n",
    "        \n",
    "        if wd in stop_words or wd == '':\n",
    "            continue\n",
    "        if wd in tf_dict:\n",
    "            tf_dict[wd] += 1\n",
    "        else:\n",
    "            tf_dict[wd] = 1\n",
    "    \n",
    "    return tf_dict\n",
    "\n",
    "\n",
    "def create_sentence_scores(sentences, tf_dict, n_chars=10):  \n",
    "    \"\"\"\n",
    "    Returns dict with (sentence, score) key-value pairs\n",
    "    \n",
    "    sentences: list of sentences\n",
    "    tf_dict: term frequency dict mapping words to num occurrences in document\n",
    "    \"\"\"\n",
    "    sentence_weight_dict = dict()\n",
    "\n",
    "    for sentence in sentences:\n",
    "        num_words = (len(word_tokenize(sentence)))\n",
    "        num_words_minus_stop_words = 0\n",
    "        first_n_chars = sentence[:n_chars]\n",
    "        \n",
    "        for word in tf_dict:\n",
    "        \n",
    "            if word in sentence.lower():\n",
    "                num_words_minus_stop_words += 1\n",
    "                \n",
    "                if not (contains_digit(first_n_chars) or contains_punctuation(first_n_chars)):\n",
    "\n",
    "                    if first_n_chars in sentence_weight_dict:\n",
    "                        sentence_weight_dict[first_n_chars] += tf_dict[word]\n",
    "                    else:\n",
    "                        sentence_weight_dict[first_n_chars] = tf_dict[word]\n",
    "        \n",
    "        if not (contains_digit(first_n_chars) or contains_punctuation(first_n_chars)):\n",
    "            # Additive smoothing to avoid divide by 0\n",
    "            sentence_weight_dict[first_n_chars] = ((sentence_weight_dict[first_n_chars]+1) / (num_words_minus_stop_words+1))\n",
    "      \n",
    "    return sentence_weight_dict\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def mean_sentence_score(sentence_weight_dict):\n",
    "    \"\"\"\n",
    "    Returns average sentence scores in a document\n",
    "    \n",
    "    sentence_weight_dict: dict with (sentence, score) key-value pairs\n",
    "    \"\"\"\n",
    "    # Calculating the average score for the sentences\n",
    "    sum_weights = 0\n",
    "    for sentence in sentence_weight_dict:\n",
    "        sum_weights += sentence_weight_dict[sentence]\n",
    "\n",
    "    # Getting sentence average value from source text\n",
    "    average_score = (sum_weights / len(sentence_weight_dict))\n",
    "\n",
    "    return average_score\n",
    "\n",
    "\n",
    "def create_summary(sentences, sentence_weight_dict, threshold, n_chars=10):\n",
    "    \"\"\"\n",
    "    Returns a summary using sentences that have sentence scores above the threshold.\n",
    "    \n",
    "    sentences: list of sentences from the case\n",
    "    sentence_weight_dict: dictionary of (sentence, sentence_score) key-value pairs\n",
    "    threshold: sentence score threshold that determines which sentences to include in the summary\n",
    "    n_chars: sentences are kept track of in a dict using the first n_chars of the sentence.\n",
    "    \"\"\"\n",
    "   \n",
    "    article_summary = ''\n",
    "    num_sentences = len(sentences)\n",
    "    \n",
    "    for sentence in sentences:\n",
    "        \n",
    "        if sentence[:n_chars] in sentence_weight_dict and sentence_weight_dict[sentence[:n_chars]] >= (threshold):\n",
    "            article_summary += \" \" + sentence\n",
    "\n",
    "    return article_summary\n",
    "\n",
    "\n",
    "def sigmoid_func(a,b,c,d):\n",
    "    return a/(1 + np.exp(-b*c)) + d\n",
    "\n",
    "def case_summary(case_text, multiplier):\n",
    "    \"\"\"\n",
    "    Returns a summary of case_text\n",
    "    \n",
    "    case_text: ranked list of dicts with fields case_name <str>, case_summary <str>, and score <float>\n",
    "    multiplier: float to threshold sentence_scores which determines what sentences are included in the case summary\n",
    "    \"\"\"\n",
    "    \n",
    "    try:\n",
    "        # create a tf dictionary\n",
    "        tf_dictionary = create_tf_dict(case_text)\n",
    "\n",
    "        # tokenize sentences\n",
    "        sentences = sent_tokenize(case_text)\n",
    "\n",
    "        # algorithm for scoring a sentence by its words\n",
    "        sentence_scores = create_sentence_scores(sentences, tf_dictionary)\n",
    "\n",
    "        # get the threshold\n",
    "        mean_sent_score = mean_sentence_score(sentence_scores)\n",
    "        \n",
    "        # produce the summary\n",
    "        case_summary = create_summary(sentences, sentence_scores, multiplier * mean_sent_score)\n",
    "        return case_summary\n",
    "    except Exception as e:\n",
    "        print(repr(e))\n",
    "        return None\n",
    "    \n",
    "def summarize_cases(results, avg, std_dev):\n",
    "    \"\"\"\n",
    "    Returns a list of dicts with fields case_name <str>, case_summary <str>, and score <float> \n",
    "    where the case_summary field is a summarized version of the full text of the court case\n",
    "    \n",
    "    results: cases relevant to query from CAP API based on the similarity of the cases's full-text to the query\n",
    "    \"\"\"\n",
    "    for case in results:\n",
    "        # this is actually the full text of the court case\n",
    "        case_text = case['case_summary']\n",
    "        # set the full text to a summarized version\n",
    "        # thresholds what sentences to include in the summary \n",
    "        try:\n",
    "            z_score = (len(sent_tokenize(case_text)) - avg) / std_dev\n",
    "        except Exception as e:\n",
    "            print(\"error caluculating z-score: \" + str(repr(e)))\n",
    "            z_score = 0\n",
    "        multiplier = sigmoid_func(2,0.5,z_score,0.25)\n",
    "        case_text_summary = case_summary(case_text, multiplier)\n",
    "        # clean up the summary\n",
    "        replacements = {'tbe' : 'the', 'Tbe' : 'The', 'bouse' : 'house', \\\n",
    "                        '•' : '', '■' : '', '- ' : ' ', ']' : '', '[' : ''}\n",
    "                        \n",
    "        if not case_text_summary is None:\n",
    "            for key in replacements:\n",
    "                print(key)\n",
    "                case_text_summary = re.sub(r\"%s\" % key, replacements[key], case_text_summary)\n",
    "           \n",
    "        # replace full-text with cleaned up summary\n",
    "        case['case_summary'] = case_text_summary\n",
    "    return results\n",
    "\n",
    "def wrap_summary(results):\n",
    "    avg = mean_case_length(results)\n",
    "    std_dev = std_dev_case_length(results)\n",
    "    return summarize_cases(results, avg, std_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tbe\n",
      "Tbe\n",
      "bouse\n",
      "•\n",
      "■\n",
      "- \n",
      "]\n",
      "[\n"
     ]
    },
    {
     "ename": "error",
     "evalue": "unterminated character set at position 0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-e9d55d543fa7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0msummarized_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwrap_summary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0msummarized_data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-11-e9319220636c>\u001b[0m in \u001b[0;36mwrap_summary\u001b[0;34m(results)\u001b[0m\n\u001b[1;32m    228\u001b[0m     \u001b[0mavg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmean_case_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m     \u001b[0mstd_dev\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstd_dev_case_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 230\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0msummarize_cases\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mavg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstd_dev\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-11-e9319220636c>\u001b[0m in \u001b[0;36msummarize_cases\u001b[0;34m(results, avg, std_dev)\u001b[0m\n\u001b[1;32m    219\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreplacements\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 221\u001b[0;31m                 \u001b[0mcase_text_summary\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msub\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mr\"%s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreplacements\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcase_text_summary\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    222\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m         \u001b[0;31m# replace full-text with cleaned up summary\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/re.py\u001b[0m in \u001b[0;36msub\u001b[0;34m(pattern, repl, string, count, flags)\u001b[0m\n\u001b[1;32m    206\u001b[0m     \u001b[0ma\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mit\u001b[0m\u001b[0;31m'\u001b[0m\u001b[0ms\u001b[0m \u001b[0mpassed\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mMatch\u001b[0m \u001b[0mobject\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mmust\u001b[0m \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m     a replacement string to be used.\"\"\"\n\u001b[0;32m--> 208\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_compile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpattern\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msub\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrepl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstring\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcount\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    209\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0msubn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpattern\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrepl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstring\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/re.py\u001b[0m in \u001b[0;36m_compile\u001b[0;34m(pattern, flags)\u001b[0m\n\u001b[1;32m    300\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msre_compile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misstring\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpattern\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    301\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"first argument must be string or compiled pattern\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 302\u001b[0;31m     \u001b[0mp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msre_compile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpattern\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    303\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mflags\u001b[0m \u001b[0;34m&\u001b[0m \u001b[0mDEBUG\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    304\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_cache\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0m_MAXCACHE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/sre_compile.py\u001b[0m in \u001b[0;36mcompile\u001b[0;34m(p, flags)\u001b[0m\n\u001b[1;32m    762\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misstring\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    763\u001b[0m         \u001b[0mpattern\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 764\u001b[0;31m         \u001b[0mp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msre_parse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    765\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    766\u001b[0m         \u001b[0mpattern\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/sre_parse.py\u001b[0m in \u001b[0;36mparse\u001b[0;34m(str, flags, state)\u001b[0m\n\u001b[1;32m    946\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    947\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 948\u001b[0;31m         \u001b[0mp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_parse_sub\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m \u001b[0;34m&\u001b[0m \u001b[0mSRE_FLAG_VERBOSE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    949\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mVerbose\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    950\u001b[0m         \u001b[0;31m# the VERBOSE flag was switched on inside the pattern.  to be\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/sre_parse.py\u001b[0m in \u001b[0;36m_parse_sub\u001b[0;34m(source, state, verbose, nested)\u001b[0m\n\u001b[1;32m    441\u001b[0m     \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msource\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtell\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    442\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 443\u001b[0;31m         itemsappend(_parse(source, state, verbose, nested + 1,\n\u001b[0m\u001b[1;32m    444\u001b[0m                            not nested and not items))\n\u001b[1;32m    445\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msourcematch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"|\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/sre_parse.py\u001b[0m in \u001b[0;36m_parse\u001b[0;34m(source, state, verbose, nested, first)\u001b[0m\n\u001b[1;32m    547\u001b[0m                 \u001b[0mthis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msourceget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    548\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mthis\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 549\u001b[0;31m                     raise source.error(\"unterminated character set\",\n\u001b[0m\u001b[1;32m    550\u001b[0m                                        source.tell() - here)\n\u001b[1;32m    551\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mthis\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"]\"\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31merror\u001b[0m: unterminated character set at position 0"
     ]
    }
   ],
   "source": [
    "with open('output.json', 'r') as f:\n",
    "    data = json.load(f)\n",
    "    f.close()\n",
    "summarized_data = wrap_summary(data)\n",
    "\n",
    "summarized_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
